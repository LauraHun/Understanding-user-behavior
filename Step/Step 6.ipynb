{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 – Two approaches: Logistic regression & K-means\n",
    "\n",
    "This notebook:\n",
    "- **Logistic regression**: Predict interface version (A vs B) from session-level behavioral features.\n",
    "- **K-means clustering**: Group sessions by behavior (unsupervised).\n",
    "\n",
    "For each we evaluate: **model performance**, **feature importance** (or ranking), and **failure cases**.\n",
    "\n",
    "Deliverables: **results summary**, **feature importance ranking**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load or build session-level dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, silhouette_score, silhouette_samples,\n",
    ")\n",
    "\n",
    "BASE = Path(\"..\")\n",
    "\n",
    "# Try loading precomputed session-level metrics; otherwise compute from logs\n",
    "session_path = BASE / \"session_level_metrics.csv\"\n",
    "if session_path.exists():\n",
    "    session_level = pd.read_csv(session_path)\n",
    "else:\n",
    "    logs = pd.read_csv(BASE / \"logs.csv\")\n",
    "    sessions = pd.read_csv(BASE / \"sessions.csv\")\n",
    "    logs[\"timestamp\"] = pd.to_datetime(logs[\"timestamp\"])\n",
    "    logs = logs.sort_values([\"session_id\", \"timestamp\"])\n",
    "    logs[\"prev_timestamp\"] = logs.groupby(\"session_id\")[\"timestamp\"].shift(1)\n",
    "    logs[\"gap_sec\"] = (logs[\"timestamp\"] - logs[\"prev_timestamp\"]).dt.total_seconds()\n",
    "    logs[\"prev_action\"] = logs.groupby(\"session_id\")[\"action_type\"].shift(1)\n",
    "    logs[\"prev_element\"] = logs.groupby(\"session_id\")[\"element_id\"].shift(1)\n",
    "    logs[\"is_repetition\"] = (logs[\"action_type\"] == logs[\"prev_action\"]) & (logs[\"element_id\"] == logs[\"prev_element\"])\n",
    "    logs[\"action_element\"] = logs[\"action_type\"].astype(str) + \"_\" + logs[\"element_id\"].astype(str)\n",
    "    session_duration = (logs.groupby(\"session_id\")[\"timestamp\"].max() - logs.groupby(\"session_id\")[\"timestamp\"].min()).dt.total_seconds()\n",
    "    n_actions = logs.groupby(\"session_id\").size()\n",
    "    duration_min = (session_duration / 60).replace(0, np.nan)\n",
    "    session_level = pd.DataFrame({\n",
    "        \"session_id\": n_actions.index,\n",
    "        \"usage_intensity\": n_actions.values,\n",
    "        \"session_duration_sec\": session_duration.values,\n",
    "        \"actions_per_minute\": (n_actions / duration_min).values,\n",
    "        \"error_proportion\": logs.groupby(\"session_id\")[\"error_flag\"].mean().values,\n",
    "        \"hesitation_time_sec\": logs.groupby(\"session_id\")[\"gap_sec\"].mean().values,\n",
    "        \"action_diversity\": logs.groupby(\"session_id\")[\"action_element\"].nunique().values,\n",
    "        \"repetition_index\": logs.groupby(\"session_id\")[\"is_repetition\"].mean().values,\n",
    "    })\n",
    "    sessions_clean = sessions.drop_duplicates(subset=[\"session_id\"])\n",
    "    session_level = session_level.merge(sessions_clean, on=\"session_id\", how=\"left\")\n",
    "\n",
    "feature_cols = [\"usage_intensity\", \"error_proportion\", \"hesitation_time_sec\", \"action_diversity\", \"repetition_index\"]\n",
    "if \"actions_per_minute\" in session_level.columns:\n",
    "    feature_cols.append(\"actions_per_minute\")\n",
    "\n",
    "df = session_level.copy()\n",
    "df[\"target\"] = (df[\"interface_version\"] == \"B\").astype(int)  # B=1, A=0\n",
    "\n",
    "for c in feature_cols:\n",
    "    if c in df.columns and df[c].isna().any():\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "df = df.dropna(subset=feature_cols + [\"target\"]).reset_index(drop=True)\n",
    "print(f\"Sessions with complete features and target: {len(df)}\")\n",
    "df[feature_cols + [\"interface_version\", \"target\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train/test split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_cols]\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "X_s = scaler.fit_transform(X)  # full data for K-means\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Approach 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_s, y_train)\n",
    "y_pred_lr = lr.predict(X_test_s)\n",
    "y_proba_lr = lr.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_lr)\n",
    "prec = precision_score(y_test, y_pred_lr, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred_lr, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred_lr, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_proba_lr) if len(np.unique(y_test)) > 1 else 0.5\n",
    "\n",
    "print(\"Logistic regression – Performance (test set):\")\n",
    "print(f\"  Accuracy:  {acc:.4f}\")\n",
    "print(f\"  Precision: {prec:.4f}\")\n",
    "print(f\"  Recall:   {rec:.4f}\")\n",
    "print(f\"  F1:       {f1:.4f}\")\n",
    "print(f\"  ROC-AUC:  {auc:.4f}\")\n",
    "print(\"\\nConfusion matrix (test):\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance: absolute coefficient (standardized features)\n",
    "coef = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"coefficient\": lr.coef_[0],\n",
    "})\n",
    "coef[\"abs_coef\"] = np.abs(coef[\"coefficient\"])\n",
    "coef = coef.sort_values(\"abs_coef\", ascending=False).reset_index(drop=True)\n",
    "coef[\"rank\"] = range(1, len(coef) + 1)\n",
    "print(\"Logistic regression – Feature importance (coefficients on standardized features):\")\n",
    "coef[[\"rank\", \"feature\", \"coefficient\", \"abs_coef\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failure cases: misclassified sessions (test set)\n",
    "test_idx = X_test.index\n",
    "df_test = df.loc[test_idx].copy()\n",
    "df_test[\"predicted\"] = y_pred_lr\n",
    "df_test[\"predicted_label\"] = df_test[\"predicted\"].map({0: \"A\", 1: \"B\"})\n",
    "df_test[\"correct\"] = df_test[\"target\"] == df_test[\"predicted\"]\n",
    "failures_lr = df_test[~df_test[\"correct\"]].copy()\n",
    "\n",
    "print(f\"Failure cases (misclassified): {len(failures_lr)} out of {len(df_test)} test sessions\")\n",
    "if len(failures_lr) > 0:\n",
    "    cols_show = [\"session_id\", \"interface_version\", \"predicted_label\"] + [c for c in feature_cols if c in failures_lr.columns]\n",
    "    display(failures_lr[cols_show].head(10))\n",
    "else:\n",
    "    print(\"No misclassifications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Approach 2: K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2  # match A/B; can try 3–4 and compare silhouette\n",
    "km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "km.fit(X_s)\n",
    "labels_km = km.labels_\n",
    "\n",
    "sil_avg = silhouette_score(X_s, labels_km)\n",
    "sil_samples = silhouette_samples(X_s, labels_km)\n",
    "\n",
    "print(f\"K-means (k={k}) – Performance:\")\n",
    "print(f\"  Inertia: {km.inertia_:.2f}\")\n",
    "print(f\"  Silhouette score (avg): {sil_avg:.4f}\")\n",
    "print(\"\\nCluster sizes:\")\n",
    "print(pd.Series(labels_km).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance ranking for K-means: which features differ most across cluster centroids\n",
    "centroids = pd.DataFrame(km.cluster_centers_, columns=feature_cols)\n",
    "centroids[\"cluster\"] = range(k)\n",
    "centroid_range = centroids[feature_cols].max() - centroids[feature_cols].min()\n",
    "feat_importance_km = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"range_across_centroids\": centroid_range.values,\n",
    "}).sort_values(\"range_across_centroids\", ascending=False)\n",
    "feat_importance_km[\"rank\"] = range(1, len(feat_importance_km) + 1)\n",
    "print(\"K-means – Feature importance ranking (range of centroid values; larger = more separation):\")\n",
    "feat_importance_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failure cases: sessions with lowest silhouette (ambiguous assignment)\n",
    "df[\"cluster\"] = labels_km\n",
    "df[\"silhouette\"] = sil_samples\n",
    "n_fail = min(10, max(1, int(0.1 * len(df))))\n",
    "failures_km = df.nsmallest(n_fail, \"silhouette\")[[\"session_id\", \"cluster\", \"silhouette\"] + feature_cols]\n",
    "\n",
    "print(f\"Failure cases (lowest silhouette, ambiguous assignment): top {n_fail} sessions\")\n",
    "display(failures_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = pd.DataFrame([\n",
    "    {\n",
    "        \"Approach\": \"Logistic regression\",\n",
    "        \"Task\": \"Predict interface_version (A vs B)\",\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"F1\": round(f1, 4),\n",
    "        \"ROC-AUC\": round(auc, 4),\n",
    "        \"Failure_cases\": len(failures_lr),\n",
    "        \"Failure_note\": \"Misclassified test sessions\",\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": \"K-means (k=2)\",\n",
    "        \"Task\": \"Cluster sessions by behavior\",\n",
    "        \"Accuracy\": np.nan,\n",
    "        \"F1\": np.nan,\n",
    "        \"ROC-AUC\": np.nan,\n",
    "        \"Failure_cases\": n_fail,\n",
    "        \"Failure_note\": \"Lowest silhouette (ambiguous)\",\n",
    "    },\n",
    "])\n",
    "results_summary[\"Silhouette\"] = [np.nan, round(sil_avg, 4)]\n",
    "results_summary[\"Inertia\"] = [np.nan, round(km.inertia_, 2)]\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature importance ranking (combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rank = coef[[\"feature\", \"rank\", \"coefficient\"]].rename(columns={\"rank\": \"LR_rank\", \"coefficient\": \"LR_coef\"})\n",
    "km_rank = feat_importance_km[[\"feature\", \"rank\", \"range_across_centroids\"]].rename(\n",
    "    columns={\"rank\": \"KMeans_rank\", \"range_across_centroids\": \"KMeans_centroid_range\"}\n",
    ")\n",
    "importance_ranking = lr_rank.merge(km_rank, on=\"feature\", how=\"outer\")\n",
    "importance_ranking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
